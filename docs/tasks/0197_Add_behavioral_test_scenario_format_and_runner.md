---
name: Add behavioral test scenario format and runner
description: Define tests/scenarios.yaml schema for behavioral testing, create runner infrastructure, integrate scoring with evaluation pipeline
status: Completed
created_at: 2026-02-11 15:49:01
updated_at: 2026-02-11 21:32:39
impl_progress:
  planning: completed
  design: completed
  implementation: completed
  review: completed
  testing: completed
  planning: pending
  design: pending
  implementation: pending
  review: pending
  testing: pending
---

## 0197. Add behavioral test scenario format and runner

### Background

Part of task 0190 (Phase 3). The cc-skills evaluation-first methodology recommends testing skills against real scenarios, but there's no standardized format for test scenarios. This task formalizes a `tests/scenarios.yaml` schema per skill that defines expected inputs, behaviors, and anti-behaviors. Per Anthropic: "Start small: 20-50 simple tasks drawn from real failures." Per the ArXiv 4-pillar framework: behavioral testing reveals "agents that complete tasks while violating policies."

Target files: `plugins/rd2/skills/cc-skills/scripts/evaluators/behavioral.py`, schema in `references/scenario-schema.yaml`

### Requirements

- [ ] Define `tests/scenarios.yaml` YAML schema with: name, input, expected_behaviors, anti_behaviors, difficulty
- [ ] Create schema documentation in `references/scenario-schema.md`
- [ ] Create `behavioral.py` evaluator that parses scenario files and scores coverage
- [ ] Add `skills.py test` command for running behavioral tests (dry-run mode: validate schema only)
- [ ] Integrate scenario presence/quality into the behavioral_readiness evaluator scoring
- [ ] Create scenario templates for common skill types (technique, pattern, reference)
- [ ] All existing tests pass
- [ ] New unit tests for schema validation and scoring

### Q&A

[Clarifications added during planning phase]

### Design

[Architecture/UI specs added by specialists]

### Solution


## Solution Status

**Approach**: Behavioral test scenario format and runner NOT YET IMPLEMENTED.

### Work Required

1. Create `scripts/evaluators/behavioral.py` - scenario parser and runner
2. Create `references/scenario-schema.yaml` - YAML schema for tests/scenarios.yaml
3. Create `references/scenario-schema.md` - schema documentation
4. Add behavioral tests integration with behavioral_readiness evaluator

### Files to Create
- `plugins/rd2/skills/cc-skills/scripts/evaluators/behavioral.py`
- `plugins/rd2/skills/cc-skills/references/scenario-schema.yaml`
- `plugins/rd2/skills/cc-skills/references/scenario-schema.md`

### Dependencies
- Depends on behavioral_readiness.py (already exists)

**Status**: Ready for implementation

### Plan

[Step-by-step implementation plan]

### Artifacts

| Type | Path | Generated By | Date |
| ---- | ---- | ------------ | ---- |

### References

- Parent: docs/tasks/0190_enhance_Agent_Skills_cc-skills.md
- Brainstorm: docs/.tasks/brainstorm/0190_brainstorm.md
- Evaluation-first methodology: plugins/rd2/skills/cc-skills/references/evaluation.md
- TDD for skills: plugins/rd2/skills/cc-skills/references/tdd-for-skills.md
- Depends on: 0194 (behavioral_readiness evaluator)
