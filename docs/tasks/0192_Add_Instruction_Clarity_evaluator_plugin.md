---
name: Add Instruction Clarity evaluator plugin
description: Create evaluator plugin that scores instruction clarity - ambiguity detection, imperative form enforcement, actionable guidance assessment
status: Completed
created_at: 2026-02-11 15:49:01
updated_at: 2026-02-11 18:01:38
impl_progress:
  planning: completed
  design: completed
  implementation: completed
  review: completed
  testing: completed
  planning: pending
  design: pending
  implementation: pending
  review: pending
  testing: pending
---

## 0192. Add Instruction Clarity evaluator plugin

### Background

Part of task 0190 (Phase 1). Current evaluation checks writing style superficially (imperative form) but doesn't assess whether instructions are actually clear and unambiguous for an AI agent to follow. Per Anthropic's eval framework: "A good task is one where two domain experts would independently reach the same pass/fail verdict" - same principle applies to skill instructions. Per ArXiv 4-pillar framework: instruction adherence is a core LLM evaluation pillar.

Target file: `plugins/rd2/skills/cc-skills/scripts/evaluators/instruction_clarity.py`
Weight: 10%

### Requirements

- [ ] Create `instruction_clarity.py` evaluator implementing `DimensionEvaluator` protocol
- [ ] Detect ambiguous language patterns: "might", "could", "maybe", "as needed", "if appropriate" without clear criteria
- [ ] Check imperative form ratio (imperative sentences / total sentences)
- [ ] Score actionability: percentage of instructions that reference specific tools, files, or commands
- [ ] Detect conditional instructions without clear branching criteria ("if X, do Y" where X is vague)
- [ ] Check for contradictory instructions within the skill
- [ ] Use rubric-based scoring
- [ ] All existing tests pass
- [ ] New unit tests for the evaluator

### Q&A

[Clarifications added during planning phase]

### Design

[Architecture/UI specs added by specialists]

### Solution


Approach: Create a new `instruction_clarity.py` evaluator plugin that assesses how clearly a skill communicates its instructions to Claude. This evaluator checks for imperative writing form, clear step sequences, unambiguous directives, and avoidance of vague language. It follows the existing DimensionEvaluator protocol pattern.

Key decisions:
- Evaluator checks: imperative vs passive voice, step clarity, action verb usage, vague language detection, conditional clarity
- Scoring criteria: imperative form usage (30%), step sequence clarity (25%), action verb presence (25%), vague language avoidance (20%)
- Analyze SKILL.md body content for instruction patterns
- Return structured findings with score, issues list, and suggestions

Files to create/modify:
- `plugins/rd2/skills/cc-skills/scripts/evaluators/instruction_clarity.py` -- New evaluator implementing DimensionEvaluator protocol
- `plugins/rd2/skills/cc-skills/scripts/evaluators/__init__.py` -- Add InstructionClarityEvaluator to exports
- `plugins/rd2/skills/cc-skills/tests/test_instruction_clarity.py` -- Unit tests

Acceptance criteria:
- Implements DimensionEvaluator protocol (name, weight, evaluate methods)
- Correctly scores skills based on instruction clarity
- Detects passive voice, vague language, missing action verbs
- Exports from __init__.py for auto-discovery
- Unit tests pass
- Existing tests unaffected

### Plan

[Step-by-step implementation plan]

### Artifacts

| Type | Path | Generated By | Date |
| ---- | ---- | ------------ | ---- |

### References

- Parent: docs/tasks/0190_enhance_Agent_Skills_cc-skills.md
- Brainstorm: docs/.tasks/brainstorm/0190_brainstorm.md
- Existing evaluators: plugins/rd2/skills/cc-skills/scripts/evaluators/
- Writing style guide: plugins/rd2/skills/cc-skills/references/writing-style.md
